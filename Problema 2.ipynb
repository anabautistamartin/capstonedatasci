{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5a73fc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "import sklearn as sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "769d2f5c",
   "metadata": {},
   "source": [
    "## 1. Preparando los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40066472",
   "metadata": {},
   "source": [
    "Llamaremos al DataFrame 'data' de momento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8c3dc569",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://github.com/anabautistamartin/capstonedatasci/files/8984239/dataset.csv', sep=';', header=None, decimal=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e866cb",
   "metadata": {},
   "source": [
    "### Poniendo nombre a las columnas y reorganizándolas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6fa75f",
   "metadata": {},
   "source": [
    "Queremos que el DataFrame quede en el orden 'version', 'item', 'ms', 'lang', 'expo', 'pref', 'use', 'grupo', 'orden', 'contextlab1' y 'contextlab2'. 'Version', que es la versión del ítem (correcta o incorrecta) y lo que buscamos predecir, pasará a llamarse **'predict'**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9eea89da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      predict  item          ms  lang  expo  pref       use  profic  grupo  \\\n",
      "0           1    76  110.037736     0  0.90  0.50  0.875000   1.000      0   \n",
      "1           1    76   92.905660     0  0.80  0.50  0.806250   0.900      0   \n",
      "2           1    76   84.207547     0  0.50  0.60  0.912500   0.950      0   \n",
      "3           1    76   63.169811     0  0.95  0.90  0.887500   0.900      0   \n",
      "4           1    76   62.452830     0  0.60  0.70  0.787500   1.000      0   \n",
      "...       ...   ...         ...   ...   ...   ...       ...     ...    ...   \n",
      "7520        0    69   62.932584     1  0.45  0.35  0.361429   0.850      1   \n",
      "7521        0    69  185.112360     1  0.02  0.30  0.050000   0.925      1   \n",
      "7522        0    69  128.617977     1  0.10  0.40  0.014286   0.775      1   \n",
      "7523        0    69   74.932584     1  0.60  0.60  0.556250   1.000      1   \n",
      "7524        0    69   84.865169     1  0.30  0.25  0.234286   0.975      1   \n",
      "\n",
      "      orden  contextlab1  contextlab2  \n",
      "0         0            0            0  \n",
      "1         0            0            0  \n",
      "2         0            0            0  \n",
      "3         0            0            0  \n",
      "4         0            0            0  \n",
      "...     ...          ...          ...  \n",
      "7520      1            1            1  \n",
      "7521      1            1            1  \n",
      "7522      1            1            1  \n",
      "7523      1            1            1  \n",
      "7524      1            1            1  \n",
      "\n",
      "[7525 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "data.columns = ['predict', 'item', 'ms', 'lang', 'expo', 'pref', 'use', 'profic', 'grupo', 'orden', 'contextlab1', 'contextlab2']\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078dc4e9",
   "metadata": {},
   "source": [
    "### Haciendo one-hot-encoding de la columna 'item'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5859048",
   "metadata": {},
   "source": [
    "La variable 'item' es una variable categórica que indica, del 1 al 146, el número de ítem que lee el sujeto en cada ensayo, esto es, en cada línea del DataFrame. Para un procesamiento adecuado, esta variable se tiene que descomponer en variables dicotómicas con los valores 0 y 1. Generamos, entonces, un DataFrame que incluya todas las variables dicotómicas de 'item', llamado 'dataset'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2df02e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      predict          ms  lang  expo  pref       use  profic  grupo  orden  \\\n",
      "0           1  110.037736     0  0.90  0.50  0.875000   1.000      0      0   \n",
      "1           1   92.905660     0  0.80  0.50  0.806250   0.900      0      0   \n",
      "2           1   84.207547     0  0.50  0.60  0.912500   0.950      0      0   \n",
      "3           1   63.169811     0  0.95  0.90  0.887500   0.900      0      0   \n",
      "4           1   62.452830     0  0.60  0.70  0.787500   1.000      0      0   \n",
      "...       ...         ...   ...   ...   ...       ...     ...    ...    ...   \n",
      "7520        0   62.932584     1  0.45  0.35  0.361429   0.850      1      1   \n",
      "7521        0  185.112360     1  0.02  0.30  0.050000   0.925      1      1   \n",
      "7522        0  128.617977     1  0.10  0.40  0.014286   0.775      1      1   \n",
      "7523        0   74.932584     1  0.60  0.60  0.556250   1.000      1      1   \n",
      "7524        0   84.865169     1  0.30  0.25  0.234286   0.975      1      1   \n",
      "\n",
      "      contextlab1  ...  136  137  138  140  141  142  143  144  145  146  \n",
      "0               0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "1               0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "2               0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "3               0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "4               0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "...           ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "7520            1  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7521            1  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7522            1  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7523            1  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7524            1  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[7525 rows x 156 columns]\n"
     ]
    }
   ],
   "source": [
    "dummies_item = pd.get_dummies(data['item'])\n",
    "\n",
    "dataset = pd.merge(\n",
    "    left=data,\n",
    "    right=dummies_item,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "del dataset['item']\n",
    "\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36e3236",
   "metadata": {},
   "source": [
    "### Eliminando las variables 'contextlab1' y 'contextlab2'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe35eda",
   "metadata": {},
   "source": [
    "Eliminamos las variables referidas a la condición experimental 'contextlab1' y 'contextlab2' porque, junto a la variable que indica el número del ítem, codifican la versión de la oración que lee el sujeto. En otras palabras, la versión (correcta o incorrecta) de cada ítem que se presentaba a los participantes venía dada por la condición experimental. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6920027",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      predict          ms  lang  expo  pref       use  profic  grupo  orden  \\\n",
      "0           1  110.037736     0  0.90  0.50  0.875000   1.000      0      0   \n",
      "1           1   92.905660     0  0.80  0.50  0.806250   0.900      0      0   \n",
      "2           1   84.207547     0  0.50  0.60  0.912500   0.950      0      0   \n",
      "3           1   63.169811     0  0.95  0.90  0.887500   0.900      0      0   \n",
      "4           1   62.452830     0  0.60  0.70  0.787500   1.000      0      0   \n",
      "...       ...         ...   ...   ...   ...       ...     ...    ...    ...   \n",
      "7520        0   62.932584     1  0.45  0.35  0.361429   0.850      1      1   \n",
      "7521        0  185.112360     1  0.02  0.30  0.050000   0.925      1      1   \n",
      "7522        0  128.617977     1  0.10  0.40  0.014286   0.775      1      1   \n",
      "7523        0   74.932584     1  0.60  0.60  0.556250   1.000      1      1   \n",
      "7524        0   84.865169     1  0.30  0.25  0.234286   0.975      1      1   \n",
      "\n",
      "      1  ...  136  137  138  140  141  142  143  144  145  146  \n",
      "0     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "1     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "2     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "3     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "4     0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "...  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "7520  0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7521  0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7522  0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7523  0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7524  0  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[7525 rows x 154 columns]\n"
     ]
    }
   ],
   "source": [
    "del dataset['contextlab1']\n",
    "del dataset['contextlab2']\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ab607f",
   "metadata": {},
   "source": [
    "### Normalizando 'ms'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fc938e",
   "metadata": {},
   "source": [
    "La variable 'ms' indica el tiempo de lectura del ítem en milisegundos en cada ensayo, ponderado según la longitud del ítem en número de caracteres. Esta variable tiene un rango diferente a las demás variables, y por eso procedemos a normalizarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ee91826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0.227130\n",
      "1       0.187630\n",
      "2       0.167576\n",
      "3       0.119072\n",
      "4       0.117419\n",
      "          ...   \n",
      "7520    0.118525\n",
      "7521    0.400220\n",
      "7522    0.269968\n",
      "7523    0.146192\n",
      "7524    0.169092\n",
      "Name: ms, Length: 7525, dtype: float64\n",
      "      predict        ms  lang  expo  pref       use  profic  grupo  orden  1  \\\n",
      "0           1  0.227130     0  0.90  0.50  0.875000   1.000      0      0  0   \n",
      "1           1  0.187630     0  0.80  0.50  0.806250   0.900      0      0  0   \n",
      "2           1  0.167576     0  0.50  0.60  0.912500   0.950      0      0  0   \n",
      "3           1  0.119072     0  0.95  0.90  0.887500   0.900      0      0  0   \n",
      "4           1  0.117419     0  0.60  0.70  0.787500   1.000      0      0  0   \n",
      "...       ...       ...   ...   ...   ...       ...     ...    ...    ... ..   \n",
      "7520        0  0.118525     1  0.45  0.35  0.361429   0.850      1      1  0   \n",
      "7521        0  0.400220     1  0.02  0.30  0.050000   0.925      1      1  0   \n",
      "7522        0  0.269968     1  0.10  0.40  0.014286   0.775      1      1  0   \n",
      "7523        0  0.146192     1  0.60  0.60  0.556250   1.000      1      1  0   \n",
      "7524        0  0.169092     1  0.30  0.25  0.234286   0.975      1      1  0   \n",
      "\n",
      "      ...  136  137  138  140  141  142  143  144  145  146  \n",
      "0     ...    0    0    0    0    0    0    0    0    0    0  \n",
      "1     ...    0    0    0    0    0    0    0    0    0    0  \n",
      "2     ...    0    0    0    0    0    0    0    0    0    0  \n",
      "3     ...    0    0    0    0    0    0    0    0    0    0  \n",
      "4     ...    0    0    0    0    0    0    0    0    0    0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "7520  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7521  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7522  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7523  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "7524  ...    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[7525 rows x 154 columns]\n"
     ]
    }
   ],
   "source": [
    "dataset['ms'] = MinMaxScaler().fit_transform(np.array(dataset['ms']).reshape(-1,1)) \n",
    "  \n",
    "print(dataset['ms'])\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5dbd4b9",
   "metadata": {},
   "source": [
    "### Separando la variable a predecir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a825c3",
   "metadata": {},
   "source": [
    "Queremos predecir la versión del ítem que se presenta en cada ensayo, que corresponde a la variable 'predict'. La separamos del resto del dataset bajo el nombre 'tags'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "934f781b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       1\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       1\n",
      "       ..\n",
      "7520    0\n",
      "7521    0\n",
      "7522    0\n",
      "7523    0\n",
      "7524    0\n",
      "Name: predict, Length: 7525, dtype: int64\n",
      "            ms  lang  expo  pref       use  profic  grupo  orden  1  2  ...  \\\n",
      "0     0.227130     0  0.90  0.50  0.875000   1.000      0      0  0  0  ...   \n",
      "1     0.187630     0  0.80  0.50  0.806250   0.900      0      0  0  0  ...   \n",
      "2     0.167576     0  0.50  0.60  0.912500   0.950      0      0  0  0  ...   \n",
      "3     0.119072     0  0.95  0.90  0.887500   0.900      0      0  0  0  ...   \n",
      "4     0.117419     0  0.60  0.70  0.787500   1.000      0      0  0  0  ...   \n",
      "...        ...   ...   ...   ...       ...     ...    ...    ... .. ..  ...   \n",
      "7520  0.118525     1  0.45  0.35  0.361429   0.850      1      1  0  0  ...   \n",
      "7521  0.400220     1  0.02  0.30  0.050000   0.925      1      1  0  0  ...   \n",
      "7522  0.269968     1  0.10  0.40  0.014286   0.775      1      1  0  0  ...   \n",
      "7523  0.146192     1  0.60  0.60  0.556250   1.000      1      1  0  0  ...   \n",
      "7524  0.169092     1  0.30  0.25  0.234286   0.975      1      1  0  0  ...   \n",
      "\n",
      "      136  137  138  140  141  142  143  144  145  146  \n",
      "0       0    0    0    0    0    0    0    0    0    0  \n",
      "1       0    0    0    0    0    0    0    0    0    0  \n",
      "2       0    0    0    0    0    0    0    0    0    0  \n",
      "3       0    0    0    0    0    0    0    0    0    0  \n",
      "4       0    0    0    0    0    0    0    0    0    0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "7520    0    0    0    0    0    0    0    0    0    0  \n",
      "7521    0    0    0    0    0    0    0    0    0    0  \n",
      "7522    0    0    0    0    0    0    0    0    0    0  \n",
      "7523    0    0    0    0    0    0    0    0    0    0  \n",
      "7524    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[7525 rows x 153 columns]\n"
     ]
    }
   ],
   "source": [
    "tags = dataset[\"predict\"]\n",
    "print(tags)\n",
    "\n",
    "variables = dataset\n",
    "del variables['predict']\n",
    "print(variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1937ad6",
   "metadata": {},
   "source": [
    "### Separando los sets de Train y Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbca2d7",
   "metadata": {},
   "source": [
    "En este caso destinamos un 80% de los datos a entrenar el modelo, y un 20% a testarlo. Obtenemos así las variables X_train y y_train para entrenar el modelo, y las variables X_test y y_test para testarlo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4a904dd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ms  lang  expo  pref       use  profic  grupo  orden  1  2  ...  \\\n",
      "4504  0.221229     1  0.05  0.10  0.000000   0.925      1      0  0  0  ...   \n",
      "3640  0.110558     0  0.60  0.80  0.762500   1.000      1      0  0  0  ...   \n",
      "207   0.402552     0  0.80  0.90  0.825000   1.000      0      0  0  0  ...   \n",
      "2580  0.123159     1  0.30  0.20  0.187500   0.875      1      0  0  0  ...   \n",
      "5786  0.155662     1  0.40  0.50  0.637500   0.975      1      1  0  0  ...   \n",
      "...        ...   ...   ...   ...       ...     ...    ...    ... .. ..  ...   \n",
      "1323  0.065918     0  0.80  1.00  0.912500   1.000      0      0  0  0  ...   \n",
      "1665  0.260119     0  0.60  0.50  0.712500   1.000      0      0  0  0  ...   \n",
      "7101  0.163413     1  0.45  0.35  0.361429   0.850      1      1  0  0  ...   \n",
      "351   0.301513     0  0.80  0.90  0.825000   1.000      0      0  0  0  ...   \n",
      "3698  0.103077     0  0.80  0.20  0.631250   1.000      1      0  0  0  ...   \n",
      "\n",
      "      136  137  138  140  141  142  143  144  145  146  \n",
      "4504    0    0    0    0    0    0    0    0    0    0  \n",
      "3640    0    0    0    0    0    0    0    0    0    0  \n",
      "207     0    0    0    0    0    0    0    0    0    0  \n",
      "2580    0    0    0    0    0    0    0    0    0    0  \n",
      "5786    0    0    0    0    0    0    0    0    0    0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "1323    0    0    0    0    0    0    0    0    0    0  \n",
      "1665    0    0    0    0    0    0    0    0    0    0  \n",
      "7101    0    0    0    0    0    0    0    0    0    0  \n",
      "351     0    0    0    0    0    0    0    0    0    0  \n",
      "3698    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[6020 rows x 153 columns]\n",
      "            ms  lang  expo  pref       use  profic  grupo  orden  1  2  ...  \\\n",
      "843   0.101055     0  1.00  1.00  0.912500   0.875      0      0  0  0  ...   \n",
      "3575  0.180698     1  0.25  0.10  0.225000   0.900      1      0  0  0  ...   \n",
      "6128  0.080756     1  0.15  0.10  0.257143   1.000      1      1  0  0  ...   \n",
      "822   0.107962     0  0.90  0.90  0.900000   1.000      0      0  0  0  ...   \n",
      "2617  0.078333     1  0.03  0.85  0.812500   1.000      1      0  0  0  ...   \n",
      "...        ...   ...   ...   ...       ...     ...    ...    ... .. ..  ...   \n",
      "5845  0.161175     0  0.25  0.30  0.206250   1.000      1      1  0  0  ...   \n",
      "6264  0.088829     0  0.40  0.50  0.875000   1.000      1      1  0  0  ...   \n",
      "907   0.064814     0  0.99  0.80  0.950000   1.000      0      0  0  0  ...   \n",
      "6408  0.118038     1  0.25  0.10  0.000000   0.850      1      1  0  0  ...   \n",
      "5663  0.088131     1  0.10  0.10  0.112500   0.925      1      1  0  0  ...   \n",
      "\n",
      "      136  137  138  140  141  142  143  144  145  146  \n",
      "843     0    0    0    0    0    0    0    0    0    0  \n",
      "3575    0    0    0    0    0    0    0    0    0    0  \n",
      "6128    0    0    0    0    0    0    0    0    0    1  \n",
      "822     0    0    0    0    0    0    0    0    0    0  \n",
      "2617    0    0    0    0    0    0    0    0    0    0  \n",
      "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "5845    0    0    0    0    0    0    0    0    0    0  \n",
      "6264    0    0    0    0    0    0    0    0    0    0  \n",
      "907     0    0    0    0    0    0    0    0    0    0  \n",
      "6408    0    0    0    0    0    0    0    0    0    0  \n",
      "5663    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[1505 rows x 153 columns]\n",
      "4504    1\n",
      "3640    1\n",
      "207     1\n",
      "2580    1\n",
      "5786    1\n",
      "       ..\n",
      "1323    1\n",
      "1665    0\n",
      "7101    1\n",
      "351     0\n",
      "3698    1\n",
      "Name: predict, Length: 6020, dtype: int64\n",
      "843     1\n",
      "3575    0\n",
      "6128    0\n",
      "822     1\n",
      "2617    1\n",
      "       ..\n",
      "5845    0\n",
      "6264    1\n",
      "907     1\n",
      "6408    1\n",
      "5663    1\n",
      "Name: predict, Length: 1505, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(6020, 153)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(variables, tags, test_size=0.2)\n",
    "\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "np.shape(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df5c26",
   "metadata": {},
   "source": [
    "Vemos cuántas oraciones correctas hay en el set de test, para tenerlo en cuenta al interpretar la matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be91711f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El set de test contiene un 0.532890365448505 de ensayos con oraciones correctas.\n"
     ]
    }
   ],
   "source": [
    "suma = np.sum(y_test)\n",
    "proporcion = suma/len(y_test)\n",
    "\n",
    "print(f\"El set de test contiene un {proporcion} de ensayos con oraciones correctas.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f21aab",
   "metadata": {},
   "source": [
    "### Convirtiendo las 'y' en categóricas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b3b7753",
   "metadata": {},
   "source": [
    "Convertimos las 'y', que son arrays con valores 0 y 1, en matrices bidimensiones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3cd6b1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes=2\n",
    "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00e76c5",
   "metadata": {},
   "source": [
    "## 2. Implementando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e48516",
   "metadata": {},
   "source": [
    "### Construyendo el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadcf147",
   "metadata": {},
   "source": [
    "Construimos un modelo secuencial con 14 capas de neuronas densamente conectadas. Se incluye también un dropout del 20% de neuronas cada dos capas, para reducir el riesgo de overfitting del modelo. El input para que el modelo sea entrenado es el DataFrame desarrollado anteriormente, de 153 columnas. La última neurona del modelo tiene activación **softmax** puesto que la variable a predecir, la versión del ítem, es una variable categórica con dos clases (0 y 1). Se mide la adecuación del modelo en **accuracy**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81fa8090",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, None, 36)          5544      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, None, 86)          3182      \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, None, 86)          0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, None, 100)         8700      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, None, 100)         10100     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, None, 100)         0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, None, 120)         12120     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, None, 120)         14520     \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, None, 120)         0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, None, 180)         21780     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, None, 180)         32580     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, None, 180)         0         \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, None, 120)         21720     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, None, 120)         14520     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, None, 120)         0         \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, None, 100)         12100     \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, None, 100)         10100     \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, None, 100)         0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, None, 86)          8686      \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, None, 2)           174       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 175,826\n",
      "Trainable params: 175,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential() \n",
    "model.add(Dense(36, activation='relu', input_shape=(None,153)))\n",
    "model.add(Dense(86, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(180, activation='relu'))\n",
    "model.add(Dense(180, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dense(120, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(86, activation='relu'))\n",
    "model.add(Dense(num_classes, activation='softmax'))\n",
    "\n",
    "model.summary() \n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "868309ff",
   "metadata": {},
   "source": [
    "### Entrenando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe8b2c0",
   "metadata": {},
   "source": [
    "Se entrena el modelo con un batch de 40 ejemplos, en 400 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12000efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 153) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 153), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 153).\n",
      "WARNING:tensorflow:Model was constructed with shape (None, None, 153) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 153), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 153).\n",
      "148/151 [============================>.] - ETA: 0s - loss: 0.6268 - accuracy: 0.6193WARNING:tensorflow:Model was constructed with shape (None, None, 153) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 153), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 153).\n",
      "151/151 [==============================] - 2s 6ms/step - loss: 0.6286 - accuracy: 0.6194 - val_loss: 0.5926 - val_accuracy: 0.7076\n",
      "Epoch 2/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.4055 - accuracy: 0.7774 - val_loss: 0.3361 - val_accuracy: 0.7794\n",
      "Epoch 3/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.3246 - accuracy: 0.7990 - val_loss: 0.3317 - val_accuracy: 0.7854\n",
      "Epoch 4/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.3096 - accuracy: 0.8071 - val_loss: 0.3306 - val_accuracy: 0.7854\n",
      "Epoch 5/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3093 - accuracy: 0.8056 - val_loss: 0.3251 - val_accuracy: 0.7860\n",
      "Epoch 6/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3049 - accuracy: 0.8053 - val_loss: 0.3269 - val_accuracy: 0.7854\n",
      "Epoch 7/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.3116 - accuracy: 0.8040 - val_loss: 0.3300 - val_accuracy: 0.7854\n",
      "Epoch 8/400\n",
      "151/151 [==============================] - 1s 8ms/step - loss: 0.3287 - accuracy: 0.8023 - val_loss: 0.3570 - val_accuracy: 0.7821\n",
      "Epoch 9/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.3119 - accuracy: 0.8033 - val_loss: 0.3259 - val_accuracy: 0.7854\n",
      "Epoch 10/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.3038 - accuracy: 0.8058 - val_loss: 0.3442 - val_accuracy: 0.7854\n",
      "Epoch 11/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3106 - accuracy: 0.8023 - val_loss: 0.3405 - val_accuracy: 0.7834\n",
      "Epoch 12/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3060 - accuracy: 0.8058 - val_loss: 0.3271 - val_accuracy: 0.7821\n",
      "Epoch 13/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3012 - accuracy: 0.8048 - val_loss: 0.3329 - val_accuracy: 0.7854\n",
      "Epoch 14/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3026 - accuracy: 0.8060 - val_loss: 0.3269 - val_accuracy: 0.7854\n",
      "Epoch 15/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3005 - accuracy: 0.8043 - val_loss: 0.3256 - val_accuracy: 0.7841\n",
      "Epoch 16/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.3031 - accuracy: 0.8058 - val_loss: 0.3265 - val_accuracy: 0.7854\n",
      "Epoch 17/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2990 - accuracy: 0.8051 - val_loss: 0.3411 - val_accuracy: 0.7854\n",
      "Epoch 18/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2987 - accuracy: 0.8066 - val_loss: 0.3269 - val_accuracy: 0.7854\n",
      "Epoch 19/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2937 - accuracy: 0.8060 - val_loss: 0.3260 - val_accuracy: 0.7854\n",
      "Epoch 20/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.3054 - accuracy: 0.8058 - val_loss: 0.3244 - val_accuracy: 0.7854\n",
      "Epoch 21/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2976 - accuracy: 0.8060 - val_loss: 0.3260 - val_accuracy: 0.7854\n",
      "Epoch 22/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2970 - accuracy: 0.8110 - val_loss: 0.3327 - val_accuracy: 0.7654\n",
      "Epoch 23/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2951 - accuracy: 0.8101 - val_loss: 0.3580 - val_accuracy: 0.7854\n",
      "Epoch 24/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2953 - accuracy: 0.8110 - val_loss: 0.3268 - val_accuracy: 0.7548\n",
      "Epoch 25/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.2886 - accuracy: 0.8138 - val_loss: 0.3261 - val_accuracy: 0.7681\n",
      "Epoch 26/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.2877 - accuracy: 0.8115 - val_loss: 0.3478 - val_accuracy: 0.7834\n",
      "Epoch 27/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2857 - accuracy: 0.8156 - val_loss: 0.3489 - val_accuracy: 0.7821\n",
      "Epoch 28/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2857 - accuracy: 0.8169 - val_loss: 0.3482 - val_accuracy: 0.7781\n",
      "Epoch 29/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2800 - accuracy: 0.8246 - val_loss: 0.3300 - val_accuracy: 0.7807\n",
      "Epoch 30/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2799 - accuracy: 0.8269 - val_loss: 0.3333 - val_accuracy: 0.7741\n",
      "Epoch 31/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2760 - accuracy: 0.8311 - val_loss: 0.3308 - val_accuracy: 0.7694\n",
      "Epoch 32/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2712 - accuracy: 0.8299 - val_loss: 0.3308 - val_accuracy: 0.7900\n",
      "Epoch 33/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2920 - accuracy: 0.8211 - val_loss: 0.3228 - val_accuracy: 0.7767\n",
      "Epoch 34/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2757 - accuracy: 0.8259 - val_loss: 0.3384 - val_accuracy: 0.7907\n",
      "Epoch 35/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2671 - accuracy: 0.8390 - val_loss: 0.3406 - val_accuracy: 0.7920\n",
      "Epoch 36/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2607 - accuracy: 0.8432 - val_loss: 0.4021 - val_accuracy: 0.7774\n",
      "Epoch 37/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2591 - accuracy: 0.8502 - val_loss: 0.3342 - val_accuracy: 0.7940\n",
      "Epoch 38/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2621 - accuracy: 0.8507 - val_loss: 0.3393 - val_accuracy: 0.7914\n",
      "Epoch 39/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2546 - accuracy: 0.8570 - val_loss: 0.3492 - val_accuracy: 0.7953\n",
      "Epoch 40/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2612 - accuracy: 0.8488 - val_loss: 0.3313 - val_accuracy: 0.7887\n",
      "Epoch 41/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2487 - accuracy: 0.8565 - val_loss: 0.3821 - val_accuracy: 0.7967\n",
      "Epoch 42/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2512 - accuracy: 0.8606 - val_loss: 0.3472 - val_accuracy: 0.8066\n",
      "Epoch 43/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.2454 - accuracy: 0.8631 - val_loss: 0.4132 - val_accuracy: 0.8027\n",
      "Epoch 44/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2482 - accuracy: 0.8646 - val_loss: 0.4039 - val_accuracy: 0.7934\n",
      "Epoch 45/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2437 - accuracy: 0.8663 - val_loss: 0.3667 - val_accuracy: 0.8040\n",
      "Epoch 46/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2381 - accuracy: 0.8676 - val_loss: 0.3936 - val_accuracy: 0.8000\n",
      "Epoch 47/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2331 - accuracy: 0.8721 - val_loss: 0.4343 - val_accuracy: 0.7867\n",
      "Epoch 48/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2330 - accuracy: 0.8701 - val_loss: 0.3761 - val_accuracy: 0.8000\n",
      "Epoch 49/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2292 - accuracy: 0.8787 - val_loss: 0.4323 - val_accuracy: 0.8047\n",
      "Epoch 50/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2241 - accuracy: 0.8797 - val_loss: 0.4158 - val_accuracy: 0.8073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2279 - accuracy: 0.8777 - val_loss: 0.4081 - val_accuracy: 0.8027\n",
      "Epoch 52/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2286 - accuracy: 0.8769 - val_loss: 0.3525 - val_accuracy: 0.7967\n",
      "Epoch 53/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.2179 - accuracy: 0.8860 - val_loss: 0.3779 - val_accuracy: 0.8020\n",
      "Epoch 54/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2190 - accuracy: 0.8794 - val_loss: 0.4363 - val_accuracy: 0.8066\n",
      "Epoch 55/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2205 - accuracy: 0.8817 - val_loss: 0.4597 - val_accuracy: 0.8086\n",
      "Epoch 56/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.2160 - accuracy: 0.8846 - val_loss: 0.4082 - val_accuracy: 0.7894\n",
      "Epoch 57/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2069 - accuracy: 0.8865 - val_loss: 0.3664 - val_accuracy: 0.8146\n",
      "Epoch 58/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1989 - accuracy: 0.8972 - val_loss: 0.4472 - val_accuracy: 0.8013\n",
      "Epoch 59/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2052 - accuracy: 0.8937 - val_loss: 0.4978 - val_accuracy: 0.8007\n",
      "Epoch 60/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.2065 - accuracy: 0.8942 - val_loss: 0.4857 - val_accuracy: 0.8013\n",
      "Epoch 61/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1964 - accuracy: 0.8963 - val_loss: 0.5266 - val_accuracy: 0.8027\n",
      "Epoch 62/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1991 - accuracy: 0.8980 - val_loss: 0.5144 - val_accuracy: 0.8047\n",
      "Epoch 63/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1916 - accuracy: 0.8982 - val_loss: 0.7477 - val_accuracy: 0.7980\n",
      "Epoch 64/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1967 - accuracy: 0.9023 - val_loss: 0.5614 - val_accuracy: 0.8027\n",
      "Epoch 65/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1903 - accuracy: 0.8983 - val_loss: 0.5498 - val_accuracy: 0.8007\n",
      "Epoch 66/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1940 - accuracy: 0.9002 - val_loss: 0.5169 - val_accuracy: 0.8159\n",
      "Epoch 67/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1891 - accuracy: 0.9010 - val_loss: 0.5100 - val_accuracy: 0.7940\n",
      "Epoch 68/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1888 - accuracy: 0.9061 - val_loss: 0.4710 - val_accuracy: 0.8053\n",
      "Epoch 69/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1892 - accuracy: 0.9027 - val_loss: 0.4830 - val_accuracy: 0.8106\n",
      "Epoch 70/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.2015 - accuracy: 0.8967 - val_loss: 0.3994 - val_accuracy: 0.8040\n",
      "Epoch 71/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1865 - accuracy: 0.9037 - val_loss: 0.4593 - val_accuracy: 0.8040\n",
      "Epoch 72/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1770 - accuracy: 0.9076 - val_loss: 0.4819 - val_accuracy: 0.8053\n",
      "Epoch 73/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1799 - accuracy: 0.9081 - val_loss: 0.4998 - val_accuracy: 0.8133\n",
      "Epoch 74/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1750 - accuracy: 0.9138 - val_loss: 0.5980 - val_accuracy: 0.8146\n",
      "Epoch 75/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1711 - accuracy: 0.9103 - val_loss: 0.8551 - val_accuracy: 0.8047\n",
      "Epoch 76/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1740 - accuracy: 0.9116 - val_loss: 0.4983 - val_accuracy: 0.8047\n",
      "Epoch 77/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.1746 - accuracy: 0.9083 - val_loss: 0.5079 - val_accuracy: 0.8066\n",
      "Epoch 78/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1892 - accuracy: 0.8998 - val_loss: 0.3764 - val_accuracy: 0.8066\n",
      "Epoch 79/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1700 - accuracy: 0.9146 - val_loss: 0.5767 - val_accuracy: 0.8047\n",
      "Epoch 80/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1669 - accuracy: 0.9153 - val_loss: 0.7518 - val_accuracy: 0.8120\n",
      "Epoch 81/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1645 - accuracy: 0.9148 - val_loss: 0.6090 - val_accuracy: 0.8080\n",
      "Epoch 82/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1688 - accuracy: 0.9164 - val_loss: 0.7143 - val_accuracy: 0.8140\n",
      "Epoch 83/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1670 - accuracy: 0.9169 - val_loss: 0.6194 - val_accuracy: 0.8073\n",
      "Epoch 84/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1646 - accuracy: 0.9161 - val_loss: 0.8231 - val_accuracy: 0.8159\n",
      "Epoch 85/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1708 - accuracy: 0.9100 - val_loss: 0.6599 - val_accuracy: 0.7967\n",
      "Epoch 86/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1623 - accuracy: 0.9166 - val_loss: 0.6416 - val_accuracy: 0.8040\n",
      "Epoch 87/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1620 - accuracy: 0.9135 - val_loss: 0.5353 - val_accuracy: 0.8073\n",
      "Epoch 88/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1557 - accuracy: 0.9206 - val_loss: 1.1504 - val_accuracy: 0.8047\n",
      "Epoch 89/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1608 - accuracy: 0.9188 - val_loss: 0.7062 - val_accuracy: 0.8066\n",
      "Epoch 90/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1574 - accuracy: 0.9226 - val_loss: 0.5866 - val_accuracy: 0.8080\n",
      "Epoch 91/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1599 - accuracy: 0.9191 - val_loss: 0.5022 - val_accuracy: 0.8179\n",
      "Epoch 92/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1499 - accuracy: 0.9203 - val_loss: 0.9921 - val_accuracy: 0.8113\n",
      "Epoch 93/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1540 - accuracy: 0.9228 - val_loss: 0.6261 - val_accuracy: 0.8186\n",
      "Epoch 94/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1519 - accuracy: 0.9243 - val_loss: 0.5931 - val_accuracy: 0.8133\n",
      "Epoch 95/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1535 - accuracy: 0.9246 - val_loss: 0.7056 - val_accuracy: 0.8080\n",
      "Epoch 96/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1516 - accuracy: 0.9229 - val_loss: 0.6919 - val_accuracy: 0.8093\n",
      "Epoch 97/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1556 - accuracy: 0.9216 - val_loss: 0.5153 - val_accuracy: 0.8120\n",
      "Epoch 98/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1433 - accuracy: 0.9276 - val_loss: 0.8980 - val_accuracy: 0.8126\n",
      "Epoch 99/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1416 - accuracy: 0.9291 - val_loss: 0.7925 - val_accuracy: 0.8080\n",
      "Epoch 100/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1382 - accuracy: 0.9297 - val_loss: 0.8311 - val_accuracy: 0.8093\n",
      "Epoch 101/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.2004 - accuracy: 0.9066 - val_loss: 0.4420 - val_accuracy: 0.8100\n",
      "Epoch 102/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1614 - accuracy: 0.9188 - val_loss: 0.6625 - val_accuracy: 0.8066\n",
      "Epoch 103/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1725 - accuracy: 0.9256 - val_loss: 0.6100 - val_accuracy: 0.8140\n",
      "Epoch 104/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1534 - accuracy: 0.9267 - val_loss: 0.4534 - val_accuracy: 0.8120\n",
      "Epoch 105/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1462 - accuracy: 0.9276 - val_loss: 0.5472 - val_accuracy: 0.8113\n",
      "Epoch 106/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1432 - accuracy: 0.9267 - val_loss: 0.6685 - val_accuracy: 0.8073\n",
      "Epoch 107/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1410 - accuracy: 0.9321 - val_loss: 0.7233 - val_accuracy: 0.8140\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 108/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1352 - accuracy: 0.9299 - val_loss: 0.6702 - val_accuracy: 0.8186\n",
      "Epoch 109/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1421 - accuracy: 0.9311 - val_loss: 0.8372 - val_accuracy: 0.8199\n",
      "Epoch 110/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1355 - accuracy: 0.9350 - val_loss: 0.9269 - val_accuracy: 0.8179\n",
      "Epoch 111/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1257 - accuracy: 0.9390 - val_loss: 0.7675 - val_accuracy: 0.8133\n",
      "Epoch 112/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.1325 - accuracy: 0.9357 - val_loss: 1.0010 - val_accuracy: 0.8113\n",
      "Epoch 113/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1244 - accuracy: 0.9394 - val_loss: 0.7093 - val_accuracy: 0.8199\n",
      "Epoch 114/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1284 - accuracy: 0.9385 - val_loss: 1.0305 - val_accuracy: 0.8199\n",
      "Epoch 115/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1255 - accuracy: 0.9389 - val_loss: 0.9690 - val_accuracy: 0.8179\n",
      "Epoch 116/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1248 - accuracy: 0.9415 - val_loss: 1.1702 - val_accuracy: 0.8173\n",
      "Epoch 117/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1856 - accuracy: 0.9141 - val_loss: 0.5215 - val_accuracy: 0.8186\n",
      "Epoch 118/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1389 - accuracy: 0.9326 - val_loss: 0.7516 - val_accuracy: 0.8206\n",
      "Epoch 119/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1207 - accuracy: 0.9389 - val_loss: 0.8980 - val_accuracy: 0.8252\n",
      "Epoch 120/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1289 - accuracy: 0.9379 - val_loss: 0.6686 - val_accuracy: 0.8140\n",
      "Epoch 121/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1249 - accuracy: 0.9389 - val_loss: 0.8494 - val_accuracy: 0.8179\n",
      "Epoch 122/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1211 - accuracy: 0.9410 - val_loss: 0.8637 - val_accuracy: 0.8233\n",
      "Epoch 123/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1221 - accuracy: 0.9442 - val_loss: 0.6713 - val_accuracy: 0.8233\n",
      "Epoch 124/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.1911 - accuracy: 0.9135 - val_loss: 0.5984 - val_accuracy: 0.8233\n",
      "Epoch 125/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1408 - accuracy: 0.9306 - val_loss: 0.6619 - val_accuracy: 0.8292\n",
      "Epoch 126/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.1598 - accuracy: 0.9294 - val_loss: 0.3606 - val_accuracy: 0.8286\n",
      "Epoch 127/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1536 - accuracy: 0.9224 - val_loss: 0.5308 - val_accuracy: 0.8233\n",
      "Epoch 128/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1285 - accuracy: 0.9380 - val_loss: 0.5443 - val_accuracy: 0.8206\n",
      "Epoch 129/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1305 - accuracy: 0.9419 - val_loss: 0.5355 - val_accuracy: 0.8213\n",
      "Epoch 130/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1195 - accuracy: 0.9419 - val_loss: 0.8274 - val_accuracy: 0.8279\n",
      "Epoch 131/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1198 - accuracy: 0.9427 - val_loss: 0.5039 - val_accuracy: 0.8206\n",
      "Epoch 132/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1198 - accuracy: 0.9440 - val_loss: 0.6606 - val_accuracy: 0.8252\n",
      "Epoch 133/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.1144 - accuracy: 0.9445 - val_loss: 0.7167 - val_accuracy: 0.8272\n",
      "Epoch 134/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1184 - accuracy: 0.9429 - val_loss: 0.6794 - val_accuracy: 0.8272\n",
      "Epoch 135/400\n",
      "151/151 [==============================] - 1s 8ms/step - loss: 0.1097 - accuracy: 0.9450 - val_loss: 0.6479 - val_accuracy: 0.8213\n",
      "Epoch 136/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.1166 - accuracy: 0.9447 - val_loss: 0.8757 - val_accuracy: 0.8306\n",
      "Epoch 137/400\n",
      "151/151 [==============================] - 1s 8ms/step - loss: 0.1102 - accuracy: 0.9492 - val_loss: 0.8858 - val_accuracy: 0.8339\n",
      "Epoch 138/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1173 - accuracy: 0.9457 - val_loss: 0.6325 - val_accuracy: 0.8266\n",
      "Epoch 139/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1077 - accuracy: 0.9493 - val_loss: 0.7919 - val_accuracy: 0.8365\n",
      "Epoch 140/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1090 - accuracy: 0.9468 - val_loss: 0.8013 - val_accuracy: 0.8326\n",
      "Epoch 141/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1055 - accuracy: 0.9497 - val_loss: 0.8300 - val_accuracy: 0.8312\n",
      "Epoch 142/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1108 - accuracy: 0.9503 - val_loss: 0.6385 - val_accuracy: 0.8359\n",
      "Epoch 143/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1008 - accuracy: 0.9532 - val_loss: 0.8600 - val_accuracy: 0.8306\n",
      "Epoch 144/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1035 - accuracy: 0.9542 - val_loss: 0.7772 - val_accuracy: 0.8292\n",
      "Epoch 145/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1079 - accuracy: 0.9480 - val_loss: 0.6584 - val_accuracy: 0.8385\n",
      "Epoch 146/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.1002 - accuracy: 0.9512 - val_loss: 1.0291 - val_accuracy: 0.8339\n",
      "Epoch 147/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1193 - accuracy: 0.9493 - val_loss: 0.4158 - val_accuracy: 0.8279\n",
      "Epoch 148/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1109 - accuracy: 0.9445 - val_loss: 1.1346 - val_accuracy: 0.8326\n",
      "Epoch 149/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1046 - accuracy: 0.9505 - val_loss: 0.6150 - val_accuracy: 0.8385\n",
      "Epoch 150/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0980 - accuracy: 0.9542 - val_loss: 0.8881 - val_accuracy: 0.8359\n",
      "Epoch 151/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0968 - accuracy: 0.9545 - val_loss: 1.0137 - val_accuracy: 0.8339\n",
      "Epoch 152/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0985 - accuracy: 0.9543 - val_loss: 0.7760 - val_accuracy: 0.8379\n",
      "Epoch 153/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1057 - accuracy: 0.9517 - val_loss: 0.6340 - val_accuracy: 0.8359\n",
      "Epoch 154/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1028 - accuracy: 0.9522 - val_loss: 0.6385 - val_accuracy: 0.8332\n",
      "Epoch 155/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0950 - accuracy: 0.9551 - val_loss: 0.9044 - val_accuracy: 0.8412\n",
      "Epoch 156/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0982 - accuracy: 0.9532 - val_loss: 0.6605 - val_accuracy: 0.8452\n",
      "Epoch 157/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0927 - accuracy: 0.9563 - val_loss: 1.1394 - val_accuracy: 0.8346\n",
      "Epoch 158/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1051 - accuracy: 0.9528 - val_loss: 0.5861 - val_accuracy: 0.8286\n",
      "Epoch 159/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0950 - accuracy: 0.9550 - val_loss: 0.6493 - val_accuracy: 0.8272\n",
      "Epoch 160/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0973 - accuracy: 0.9580 - val_loss: 0.6511 - val_accuracy: 0.8332\n",
      "Epoch 161/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0918 - accuracy: 0.9576 - val_loss: 0.8238 - val_accuracy: 0.8352\n",
      "Epoch 162/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0929 - accuracy: 0.9566 - val_loss: 0.5426 - val_accuracy: 0.8385\n",
      "Epoch 163/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1006 - accuracy: 0.9553 - val_loss: 0.6039 - val_accuracy: 0.8419\n",
      "Epoch 164/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0962 - accuracy: 0.9560 - val_loss: 0.7254 - val_accuracy: 0.8359\n",
      "Epoch 165/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0984 - accuracy: 0.9542 - val_loss: 0.8987 - val_accuracy: 0.8339\n",
      "Epoch 166/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1037 - accuracy: 0.9508 - val_loss: 1.0433 - val_accuracy: 0.8286\n",
      "Epoch 167/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0839 - accuracy: 0.9613 - val_loss: 1.1322 - val_accuracy: 0.8326\n",
      "Epoch 168/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0867 - accuracy: 0.9588 - val_loss: 0.9499 - val_accuracy: 0.8379\n",
      "Epoch 169/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0877 - accuracy: 0.9615 - val_loss: 1.1257 - val_accuracy: 0.8432\n",
      "Epoch 170/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0799 - accuracy: 0.9646 - val_loss: 1.2702 - val_accuracy: 0.8346\n",
      "Epoch 171/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0898 - accuracy: 0.9596 - val_loss: 0.8523 - val_accuracy: 0.8412\n",
      "Epoch 172/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0827 - accuracy: 0.9626 - val_loss: 0.8632 - val_accuracy: 0.8419\n",
      "Epoch 173/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0774 - accuracy: 0.9636 - val_loss: 0.8567 - val_accuracy: 0.8332\n",
      "Epoch 174/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0820 - accuracy: 0.9640 - val_loss: 0.9117 - val_accuracy: 0.8399\n",
      "Epoch 175/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0836 - accuracy: 0.9606 - val_loss: 0.8493 - val_accuracy: 0.8392\n",
      "Epoch 176/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0823 - accuracy: 0.9668 - val_loss: 1.1468 - val_accuracy: 0.8405\n",
      "Epoch 177/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0825 - accuracy: 0.9626 - val_loss: 0.9893 - val_accuracy: 0.8379\n",
      "Epoch 178/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1153 - accuracy: 0.9563 - val_loss: 0.3698 - val_accuracy: 0.8339\n",
      "Epoch 179/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.1012 - accuracy: 0.9565 - val_loss: 0.7405 - val_accuracy: 0.8332\n",
      "Epoch 180/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0910 - accuracy: 0.9610 - val_loss: 0.6858 - val_accuracy: 0.8339\n",
      "Epoch 181/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0787 - accuracy: 0.9625 - val_loss: 0.8493 - val_accuracy: 0.8365\n",
      "Epoch 182/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0765 - accuracy: 0.9664 - val_loss: 0.7581 - val_accuracy: 0.8419\n",
      "Epoch 183/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0842 - accuracy: 0.9626 - val_loss: 0.7154 - val_accuracy: 0.8359\n",
      "Epoch 184/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0775 - accuracy: 0.9646 - val_loss: 0.7376 - val_accuracy: 0.8485\n",
      "Epoch 185/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0802 - accuracy: 0.9630 - val_loss: 0.6861 - val_accuracy: 0.8399\n",
      "Epoch 186/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0722 - accuracy: 0.9659 - val_loss: 0.6131 - val_accuracy: 0.8385\n",
      "Epoch 187/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0834 - accuracy: 0.9623 - val_loss: 0.5694 - val_accuracy: 0.8405\n",
      "Epoch 188/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0756 - accuracy: 0.9669 - val_loss: 1.0319 - val_accuracy: 0.8372\n",
      "Epoch 189/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0855 - accuracy: 0.9623 - val_loss: 0.9429 - val_accuracy: 0.8312\n",
      "Epoch 190/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0775 - accuracy: 0.9661 - val_loss: 0.8154 - val_accuracy: 0.8419\n",
      "Epoch 191/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0754 - accuracy: 0.9663 - val_loss: 0.9147 - val_accuracy: 0.8445\n",
      "Epoch 192/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0725 - accuracy: 0.9648 - val_loss: 0.9547 - val_accuracy: 0.8412\n",
      "Epoch 193/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0668 - accuracy: 0.9701 - val_loss: 1.1868 - val_accuracy: 0.8412\n",
      "Epoch 194/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0672 - accuracy: 0.9719 - val_loss: 0.9882 - val_accuracy: 0.8458\n",
      "Epoch 195/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0924 - accuracy: 0.9633 - val_loss: 0.5904 - val_accuracy: 0.8332\n",
      "Epoch 196/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0707 - accuracy: 0.9704 - val_loss: 1.0596 - val_accuracy: 0.8492\n",
      "Epoch 197/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0797 - accuracy: 0.9681 - val_loss: 0.6662 - val_accuracy: 0.8412\n",
      "Epoch 198/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0737 - accuracy: 0.9698 - val_loss: 0.8120 - val_accuracy: 0.8472\n",
      "Epoch 199/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0786 - accuracy: 0.9694 - val_loss: 0.8847 - val_accuracy: 0.8385\n",
      "Epoch 200/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0644 - accuracy: 0.9709 - val_loss: 0.9351 - val_accuracy: 0.8352\n",
      "Epoch 201/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0815 - accuracy: 0.9679 - val_loss: 0.6459 - val_accuracy: 0.8452\n",
      "Epoch 202/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0706 - accuracy: 0.9696 - val_loss: 0.6214 - val_accuracy: 0.8405\n",
      "Epoch 203/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0646 - accuracy: 0.9728 - val_loss: 0.7470 - val_accuracy: 0.8532\n",
      "Epoch 204/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0630 - accuracy: 0.9723 - val_loss: 0.9694 - val_accuracy: 0.8472\n",
      "Epoch 205/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0679 - accuracy: 0.9711 - val_loss: 0.8742 - val_accuracy: 0.8465\n",
      "Epoch 206/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0706 - accuracy: 0.9714 - val_loss: 0.9860 - val_accuracy: 0.8385\n",
      "Epoch 207/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0810 - accuracy: 0.9699 - val_loss: 0.8767 - val_accuracy: 0.8498\n",
      "Epoch 208/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0638 - accuracy: 0.9719 - val_loss: 0.7502 - val_accuracy: 0.8405\n",
      "Epoch 209/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0717 - accuracy: 0.9718 - val_loss: 0.6567 - val_accuracy: 0.8525\n",
      "Epoch 210/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0588 - accuracy: 0.9766 - val_loss: 0.8361 - val_accuracy: 0.8545\n",
      "Epoch 211/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0752 - accuracy: 0.9714 - val_loss: 0.8503 - val_accuracy: 0.8372\n",
      "Epoch 212/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0735 - accuracy: 0.9724 - val_loss: 0.6713 - val_accuracy: 0.8425\n",
      "Epoch 213/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0636 - accuracy: 0.9738 - val_loss: 0.9029 - val_accuracy: 0.8478\n",
      "Epoch 214/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0617 - accuracy: 0.9718 - val_loss: 0.8694 - val_accuracy: 0.8452\n",
      "Epoch 215/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.0794 - accuracy: 0.9689 - val_loss: 1.0377 - val_accuracy: 0.8405\n",
      "Epoch 216/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.0693 - accuracy: 0.9696 - val_loss: 1.0984 - val_accuracy: 0.8392\n",
      "Epoch 217/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.0704 - accuracy: 0.9699 - val_loss: 0.8321 - val_accuracy: 0.8432\n",
      "Epoch 218/400\n",
      "151/151 [==============================] - 2s 12ms/step - loss: 0.0619 - accuracy: 0.9739 - val_loss: 0.8947 - val_accuracy: 0.8452\n",
      "Epoch 219/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.0693 - accuracy: 0.9723 - val_loss: 0.9921 - val_accuracy: 0.8432\n",
      "Epoch 220/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 1s 7ms/step - loss: 0.0586 - accuracy: 0.9757 - val_loss: 0.9133 - val_accuracy: 0.8518\n",
      "Epoch 221/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.0540 - accuracy: 0.9792 - val_loss: 0.9718 - val_accuracy: 0.8465\n",
      "Epoch 222/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0513 - accuracy: 0.9784 - val_loss: 1.1621 - val_accuracy: 0.8485\n",
      "Epoch 223/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0555 - accuracy: 0.9751 - val_loss: 1.1818 - val_accuracy: 0.8485\n",
      "Epoch 224/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0598 - accuracy: 0.9738 - val_loss: 0.9722 - val_accuracy: 0.8505\n",
      "Epoch 225/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0630 - accuracy: 0.9738 - val_loss: 0.7974 - val_accuracy: 0.8425\n",
      "Epoch 226/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0707 - accuracy: 0.9711 - val_loss: 0.7852 - val_accuracy: 0.8518\n",
      "Epoch 227/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0560 - accuracy: 0.9759 - val_loss: 0.8545 - val_accuracy: 0.8492\n",
      "Epoch 228/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0521 - accuracy: 0.9767 - val_loss: 0.9895 - val_accuracy: 0.8518\n",
      "Epoch 229/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0534 - accuracy: 0.9767 - val_loss: 1.0879 - val_accuracy: 0.8512\n",
      "Epoch 230/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0517 - accuracy: 0.9786 - val_loss: 0.8218 - val_accuracy: 0.8545\n",
      "Epoch 231/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0622 - accuracy: 0.9764 - val_loss: 0.7915 - val_accuracy: 0.8452\n",
      "Epoch 232/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0607 - accuracy: 0.9752 - val_loss: 1.1558 - val_accuracy: 0.8485\n",
      "Epoch 233/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0583 - accuracy: 0.9748 - val_loss: 0.9874 - val_accuracy: 0.8405\n",
      "Epoch 234/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0583 - accuracy: 0.9738 - val_loss: 0.8808 - val_accuracy: 0.8452\n",
      "Epoch 235/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0561 - accuracy: 0.9761 - val_loss: 0.9725 - val_accuracy: 0.8525\n",
      "Epoch 236/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0490 - accuracy: 0.9789 - val_loss: 1.3281 - val_accuracy: 0.8485\n",
      "Epoch 237/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0499 - accuracy: 0.9774 - val_loss: 1.2373 - val_accuracy: 0.8498\n",
      "Epoch 238/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0578 - accuracy: 0.9754 - val_loss: 1.2891 - val_accuracy: 0.8472\n",
      "Epoch 239/400\n",
      "151/151 [==============================] - 1s 3ms/step - loss: 0.0456 - accuracy: 0.9807 - val_loss: 1.5216 - val_accuracy: 0.8498\n",
      "Epoch 240/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0493 - accuracy: 0.9806 - val_loss: 1.1144 - val_accuracy: 0.8478\n",
      "Epoch 241/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0538 - accuracy: 0.9789 - val_loss: 1.1049 - val_accuracy: 0.8512\n",
      "Epoch 242/400\n",
      "151/151 [==============================] - 1s 3ms/step - loss: 0.0455 - accuracy: 0.9809 - val_loss: 1.1999 - val_accuracy: 0.8611\n",
      "Epoch 243/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0727 - accuracy: 0.9731 - val_loss: 0.8977 - val_accuracy: 0.8452\n",
      "Epoch 244/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9767 - val_loss: 1.1327 - val_accuracy: 0.8532\n",
      "Epoch 245/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9786 - val_loss: 0.9790 - val_accuracy: 0.8532\n",
      "Epoch 246/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0509 - accuracy: 0.9789 - val_loss: 0.7087 - val_accuracy: 0.8505\n",
      "Epoch 247/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0593 - accuracy: 0.9757 - val_loss: 0.8474 - val_accuracy: 0.8478\n",
      "Epoch 248/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0503 - accuracy: 0.9796 - val_loss: 0.8435 - val_accuracy: 0.8551\n",
      "Epoch 249/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0559 - accuracy: 0.9771 - val_loss: 0.6808 - val_accuracy: 0.8545\n",
      "Epoch 250/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0607 - accuracy: 0.9771 - val_loss: 0.8000 - val_accuracy: 0.8571\n",
      "Epoch 251/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0536 - accuracy: 0.9791 - val_loss: 0.8438 - val_accuracy: 0.8512\n",
      "Epoch 252/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0545 - accuracy: 0.9779 - val_loss: 0.7090 - val_accuracy: 0.8578\n",
      "Epoch 253/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0491 - accuracy: 0.9806 - val_loss: 0.9110 - val_accuracy: 0.8645\n",
      "Epoch 254/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0480 - accuracy: 0.9784 - val_loss: 0.9121 - val_accuracy: 0.8525\n",
      "Epoch 255/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0416 - accuracy: 0.9832 - val_loss: 1.1934 - val_accuracy: 0.8631\n",
      "Epoch 256/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0600 - accuracy: 0.9771 - val_loss: 0.9635 - val_accuracy: 0.8618\n",
      "Epoch 257/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9794 - val_loss: 1.0980 - val_accuracy: 0.8598\n",
      "Epoch 258/400\n",
      "151/151 [==============================] - 1s 3ms/step - loss: 0.0535 - accuracy: 0.9806 - val_loss: 0.9146 - val_accuracy: 0.8591\n",
      "Epoch 259/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0409 - accuracy: 0.9826 - val_loss: 1.2203 - val_accuracy: 0.8591\n",
      "Epoch 260/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0403 - accuracy: 0.9821 - val_loss: 0.9534 - val_accuracy: 0.8558\n",
      "Epoch 261/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9767 - val_loss: 0.8666 - val_accuracy: 0.8598\n",
      "Epoch 262/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0484 - accuracy: 0.9801 - val_loss: 1.1060 - val_accuracy: 0.8551\n",
      "Epoch 263/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0544 - accuracy: 0.9766 - val_loss: 0.8611 - val_accuracy: 0.8498\n",
      "Epoch 264/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0508 - accuracy: 0.9804 - val_loss: 0.8297 - val_accuracy: 0.8532\n",
      "Epoch 265/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0424 - accuracy: 0.9822 - val_loss: 0.9674 - val_accuracy: 0.8591\n",
      "Epoch 266/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9821 - val_loss: 1.1070 - val_accuracy: 0.8585\n",
      "Epoch 267/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0471 - accuracy: 0.9799 - val_loss: 0.8471 - val_accuracy: 0.8432\n",
      "Epoch 268/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0474 - accuracy: 0.9812 - val_loss: 0.9348 - val_accuracy: 0.8611\n",
      "Epoch 269/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1095 - accuracy: 0.9596 - val_loss: 0.4108 - val_accuracy: 0.8578\n",
      "Epoch 270/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0699 - accuracy: 0.9708 - val_loss: 0.7241 - val_accuracy: 0.8618\n",
      "Epoch 271/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0542 - accuracy: 0.9799 - val_loss: 1.1932 - val_accuracy: 0.8565\n",
      "Epoch 272/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0473 - accuracy: 0.9806 - val_loss: 1.0098 - val_accuracy: 0.8611\n",
      "Epoch 273/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0371 - accuracy: 0.9841 - val_loss: 1.4856 - val_accuracy: 0.8684\n",
      "Epoch 274/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.9822 - val_loss: 1.1837 - val_accuracy: 0.8671\n",
      "Epoch 275/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0470 - accuracy: 0.9802 - val_loss: 1.4757 - val_accuracy: 0.8591\n",
      "Epoch 276/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0515 - accuracy: 0.9807 - val_loss: 0.8788 - val_accuracy: 0.8645\n",
      "Epoch 277/400\n",
      "151/151 [==============================] - 1s 3ms/step - loss: 0.0433 - accuracy: 0.9819 - val_loss: 1.1327 - val_accuracy: 0.8571\n",
      "Epoch 278/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0614 - accuracy: 0.9776 - val_loss: 0.4850 - val_accuracy: 0.8492\n",
      "Epoch 279/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0672 - accuracy: 0.9738 - val_loss: 1.0958 - val_accuracy: 0.8585\n",
      "Epoch 280/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0450 - accuracy: 0.9821 - val_loss: 1.0754 - val_accuracy: 0.8618\n",
      "Epoch 281/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0479 - accuracy: 0.9821 - val_loss: 0.9752 - val_accuracy: 0.8638\n",
      "Epoch 282/400\n",
      "151/151 [==============================] - 1s 3ms/step - loss: 0.0419 - accuracy: 0.9816 - val_loss: 1.4542 - val_accuracy: 0.8598\n",
      "Epoch 283/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0534 - accuracy: 0.9794 - val_loss: 0.8806 - val_accuracy: 0.8638\n",
      "Epoch 284/400\n",
      "151/151 [==============================] - 1s 3ms/step - loss: 0.0389 - accuracy: 0.9859 - val_loss: 1.0876 - val_accuracy: 0.8605\n",
      "Epoch 285/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0454 - accuracy: 0.9844 - val_loss: 1.1143 - val_accuracy: 0.8671\n",
      "Epoch 286/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0352 - accuracy: 0.9867 - val_loss: 1.2497 - val_accuracy: 0.8598\n",
      "Epoch 287/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0440 - accuracy: 0.9827 - val_loss: 1.0292 - val_accuracy: 0.8625\n",
      "Epoch 288/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0430 - accuracy: 0.9836 - val_loss: 1.0671 - val_accuracy: 0.8631\n",
      "Epoch 289/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0494 - accuracy: 0.9821 - val_loss: 1.7708 - val_accuracy: 0.8585\n",
      "Epoch 290/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0495 - accuracy: 0.9827 - val_loss: 5.0631 - val_accuracy: 0.8625\n",
      "Epoch 291/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0546 - accuracy: 0.9786 - val_loss: 1.1951 - val_accuracy: 0.8611\n",
      "Epoch 292/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0432 - accuracy: 0.9826 - val_loss: 1.2944 - val_accuracy: 0.8518\n",
      "Epoch 293/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.1223 - accuracy: 0.9714 - val_loss: 0.3975 - val_accuracy: 0.8485\n",
      "Epoch 294/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0861 - accuracy: 0.9681 - val_loss: 0.8354 - val_accuracy: 0.8525\n",
      "Epoch 295/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0569 - accuracy: 0.9772 - val_loss: 1.1909 - val_accuracy: 0.8591\n",
      "Epoch 296/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0501 - accuracy: 0.9794 - val_loss: 1.2208 - val_accuracy: 0.8538\n",
      "Epoch 297/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0421 - accuracy: 0.9839 - val_loss: 1.1535 - val_accuracy: 0.8691\n",
      "Epoch 298/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0421 - accuracy: 0.9831 - val_loss: 1.2705 - val_accuracy: 0.8605\n",
      "Epoch 299/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0414 - accuracy: 0.9842 - val_loss: 1.3211 - val_accuracy: 0.8605\n",
      "Epoch 300/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0420 - accuracy: 0.9829 - val_loss: 1.2044 - val_accuracy: 0.8611\n",
      "Epoch 301/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9849 - val_loss: 1.3091 - val_accuracy: 0.8618\n",
      "Epoch 302/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0462 - accuracy: 0.9841 - val_loss: 1.2808 - val_accuracy: 0.8571\n",
      "Epoch 303/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0336 - accuracy: 0.9877 - val_loss: 2.0429 - val_accuracy: 0.8498\n",
      "Epoch 304/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0444 - accuracy: 0.9837 - val_loss: 1.2569 - val_accuracy: 0.8538\n",
      "Epoch 305/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0401 - accuracy: 0.9849 - val_loss: 1.5241 - val_accuracy: 0.8611\n",
      "Epoch 306/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0324 - accuracy: 0.9859 - val_loss: 1.5954 - val_accuracy: 0.8691\n",
      "Epoch 307/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0384 - accuracy: 0.9839 - val_loss: 1.8550 - val_accuracy: 0.8658\n",
      "Epoch 308/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0329 - accuracy: 0.9870 - val_loss: 1.4896 - val_accuracy: 0.8565\n",
      "Epoch 309/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0459 - accuracy: 0.9819 - val_loss: 1.2939 - val_accuracy: 0.8671\n",
      "Epoch 310/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0426 - accuracy: 0.9859 - val_loss: 1.1493 - val_accuracy: 0.8658\n",
      "Epoch 311/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0429 - accuracy: 0.9844 - val_loss: 0.9248 - val_accuracy: 0.8638\n",
      "Epoch 312/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0402 - accuracy: 0.9832 - val_loss: 0.9360 - val_accuracy: 0.8631\n",
      "Epoch 313/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0374 - accuracy: 0.9864 - val_loss: 1.5742 - val_accuracy: 0.8704\n",
      "Epoch 314/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0361 - accuracy: 0.9870 - val_loss: 1.3294 - val_accuracy: 0.8631\n",
      "Epoch 315/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0574 - accuracy: 0.9791 - val_loss: 1.0370 - val_accuracy: 0.8611\n",
      "Epoch 316/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0410 - accuracy: 0.9846 - val_loss: 1.1180 - val_accuracy: 0.8565\n",
      "Epoch 317/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0488 - accuracy: 0.9846 - val_loss: 0.9197 - val_accuracy: 0.8598\n",
      "Epoch 318/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0567 - accuracy: 0.9812 - val_loss: 0.9299 - val_accuracy: 0.8578\n",
      "Epoch 319/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0414 - accuracy: 0.9846 - val_loss: 0.8150 - val_accuracy: 0.8691\n",
      "Epoch 320/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0445 - accuracy: 0.9829 - val_loss: 1.1023 - val_accuracy: 0.8645\n",
      "Epoch 321/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0374 - accuracy: 0.9857 - val_loss: 0.9445 - val_accuracy: 0.8651\n",
      "Epoch 322/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0411 - accuracy: 0.9826 - val_loss: 0.9114 - val_accuracy: 0.8691\n",
      "Epoch 323/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0384 - accuracy: 0.9846 - val_loss: 1.0978 - val_accuracy: 0.8645\n",
      "Epoch 324/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0313 - accuracy: 0.9885 - val_loss: 1.0231 - val_accuracy: 0.8664\n",
      "Epoch 325/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0326 - accuracy: 0.9877 - val_loss: 1.2213 - val_accuracy: 0.8611\n",
      "Epoch 326/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0319 - accuracy: 0.9877 - val_loss: 1.2560 - val_accuracy: 0.8605\n",
      "Epoch 327/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0468 - accuracy: 0.9807 - val_loss: 1.1639 - val_accuracy: 0.8731\n",
      "Epoch 328/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0328 - accuracy: 0.9879 - val_loss: 1.3438 - val_accuracy: 0.8711\n",
      "Epoch 329/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0437 - accuracy: 0.9841 - val_loss: 1.1495 - val_accuracy: 0.8658\n",
      "Epoch 330/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0336 - accuracy: 0.9882 - val_loss: 1.3595 - val_accuracy: 0.8638\n",
      "Epoch 331/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0356 - accuracy: 0.9857 - val_loss: 1.3538 - val_accuracy: 0.8638\n",
      "Epoch 332/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0316 - accuracy: 0.9875 - val_loss: 1.6123 - val_accuracy: 0.8738\n",
      "Epoch 333/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0345 - accuracy: 0.9870 - val_loss: 1.3956 - val_accuracy: 0.8664\n",
      "Epoch 334/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0424 - accuracy: 0.9822 - val_loss: 0.8273 - val_accuracy: 0.8611\n",
      "Epoch 335/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0342 - accuracy: 0.9869 - val_loss: 1.4385 - val_accuracy: 0.8684\n",
      "Epoch 336/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0447 - accuracy: 0.9831 - val_loss: 1.4150 - val_accuracy: 0.8698\n",
      "Epoch 337/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0398 - accuracy: 0.9880 - val_loss: 0.8618 - val_accuracy: 0.8664\n",
      "Epoch 338/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0378 - accuracy: 0.9836 - val_loss: 1.0537 - val_accuracy: 0.8658\n",
      "Epoch 339/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0345 - accuracy: 0.9870 - val_loss: 1.0537 - val_accuracy: 0.8704\n",
      "Epoch 340/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0439 - accuracy: 0.9807 - val_loss: 0.7467 - val_accuracy: 0.8698\n",
      "Epoch 341/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0436 - accuracy: 0.9826 - val_loss: 1.0383 - val_accuracy: 0.8678\n",
      "Epoch 342/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0418 - accuracy: 0.9854 - val_loss: 0.8454 - val_accuracy: 0.8651\n",
      "Epoch 343/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0377 - accuracy: 0.9849 - val_loss: 1.2974 - val_accuracy: 0.8678\n",
      "Epoch 344/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0337 - accuracy: 0.9869 - val_loss: 1.5707 - val_accuracy: 0.8684\n",
      "Epoch 345/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0379 - accuracy: 0.9846 - val_loss: 1.5882 - val_accuracy: 0.8658\n",
      "Epoch 346/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0384 - accuracy: 0.9864 - val_loss: 1.2212 - val_accuracy: 0.8704\n",
      "Epoch 347/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0358 - accuracy: 0.9870 - val_loss: 1.1587 - val_accuracy: 0.8704\n",
      "Epoch 348/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0394 - accuracy: 0.9847 - val_loss: 1.1630 - val_accuracy: 0.8698\n",
      "Epoch 349/400\n",
      "151/151 [==============================] - 1s 7ms/step - loss: 0.0412 - accuracy: 0.9841 - val_loss: 1.1621 - val_accuracy: 0.8718\n",
      "Epoch 350/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0373 - accuracy: 0.9870 - val_loss: 1.3169 - val_accuracy: 0.8678\n",
      "Epoch 351/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9869 - val_loss: 2.4588 - val_accuracy: 0.8678\n",
      "Epoch 352/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0260 - accuracy: 0.9902 - val_loss: 1.9569 - val_accuracy: 0.8638\n",
      "Epoch 353/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0354 - accuracy: 0.9862 - val_loss: 1.8084 - val_accuracy: 0.8684\n",
      "Epoch 354/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0254 - accuracy: 0.9892 - val_loss: 1.9722 - val_accuracy: 0.8731\n",
      "Epoch 355/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0381 - accuracy: 0.9869 - val_loss: 1.1862 - val_accuracy: 0.8718\n",
      "Epoch 356/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0296 - accuracy: 0.9899 - val_loss: 1.6940 - val_accuracy: 0.8678\n",
      "Epoch 357/400\n",
      "151/151 [==============================] - 2s 11ms/step - loss: 0.0390 - accuracy: 0.9862 - val_loss: 1.4686 - val_accuracy: 0.8738\n",
      "Epoch 358/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0308 - accuracy: 0.9877 - val_loss: 1.8959 - val_accuracy: 0.8718\n",
      "Epoch 359/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0313 - accuracy: 0.9885 - val_loss: 2.2945 - val_accuracy: 0.8658\n",
      "Epoch 360/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0361 - accuracy: 0.9865 - val_loss: 3.4364 - val_accuracy: 0.8711\n",
      "Epoch 361/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.1293 - accuracy: 0.9721 - val_loss: 0.8409 - val_accuracy: 0.8658\n",
      "Epoch 362/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0383 - accuracy: 0.9860 - val_loss: 1.3296 - val_accuracy: 0.8651\n",
      "Epoch 363/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0458 - accuracy: 0.9826 - val_loss: 1.0396 - val_accuracy: 0.8658\n",
      "Epoch 364/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0405 - accuracy: 0.9847 - val_loss: 1.1046 - val_accuracy: 0.8605\n",
      "Epoch 365/400\n",
      "151/151 [==============================] - 1s 5ms/step - loss: 0.0419 - accuracy: 0.9880 - val_loss: 1.2560 - val_accuracy: 0.8625\n",
      "Epoch 366/400\n",
      "151/151 [==============================] - 1s 8ms/step - loss: 0.0411 - accuracy: 0.9847 - val_loss: 1.0380 - val_accuracy: 0.8691\n",
      "Epoch 367/400\n",
      "151/151 [==============================] - 1s 6ms/step - loss: 0.0310 - accuracy: 0.9895 - val_loss: 1.1515 - val_accuracy: 0.8631\n",
      "Epoch 368/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0314 - accuracy: 0.9894 - val_loss: 1.1795 - val_accuracy: 0.8664\n",
      "Epoch 369/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9907 - val_loss: 1.4107 - val_accuracy: 0.8638\n",
      "Epoch 370/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0372 - accuracy: 0.9874 - val_loss: 1.2057 - val_accuracy: 0.8645\n",
      "Epoch 371/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0351 - accuracy: 0.9872 - val_loss: 1.4092 - val_accuracy: 0.8611\n",
      "Epoch 372/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0268 - accuracy: 0.9897 - val_loss: 1.9101 - val_accuracy: 0.8718\n",
      "Epoch 373/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9884 - val_loss: 1.3539 - val_accuracy: 0.8664\n",
      "Epoch 374/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0511 - accuracy: 0.9807 - val_loss: 0.7727 - val_accuracy: 0.8684\n",
      "Epoch 375/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0285 - accuracy: 0.9892 - val_loss: 1.4060 - val_accuracy: 0.8711\n",
      "Epoch 376/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0615 - accuracy: 0.9836 - val_loss: 0.5425 - val_accuracy: 0.8611\n",
      "Epoch 377/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0387 - accuracy: 0.9860 - val_loss: 0.9938 - val_accuracy: 0.8691\n",
      "Epoch 378/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0271 - accuracy: 0.9897 - val_loss: 1.4343 - val_accuracy: 0.8671\n",
      "Epoch 379/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0222 - accuracy: 0.9917 - val_loss: 1.5727 - val_accuracy: 0.8757\n",
      "Epoch 380/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9875 - val_loss: 1.1718 - val_accuracy: 0.8718\n",
      "Epoch 381/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0373 - accuracy: 0.9864 - val_loss: 0.7564 - val_accuracy: 0.8645\n",
      "Epoch 382/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0302 - accuracy: 0.9889 - val_loss: 0.9479 - val_accuracy: 0.8651\n",
      "Epoch 383/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0284 - accuracy: 0.9894 - val_loss: 1.0612 - val_accuracy: 0.8631\n",
      "Epoch 384/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0377 - accuracy: 0.9852 - val_loss: 0.9788 - val_accuracy: 0.8691\n",
      "Epoch 385/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0415 - accuracy: 0.9829 - val_loss: 0.6770 - val_accuracy: 0.8651\n",
      "Epoch 386/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0382 - accuracy: 0.9860 - val_loss: 0.9704 - val_accuracy: 0.8684\n",
      "Epoch 387/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0310 - accuracy: 0.9887 - val_loss: 1.2415 - val_accuracy: 0.8678\n",
      "Epoch 388/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0277 - accuracy: 0.9917 - val_loss: 1.1775 - val_accuracy: 0.8664\n",
      "Epoch 389/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0225 - accuracy: 0.9925 - val_loss: 1.3489 - val_accuracy: 0.8738\n",
      "Epoch 390/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0739 - accuracy: 0.9814 - val_loss: 0.7629 - val_accuracy: 0.8691\n",
      "Epoch 391/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0249 - accuracy: 0.9900 - val_loss: 1.0654 - val_accuracy: 0.8658\n",
      "Epoch 392/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0254 - accuracy: 0.9904 - val_loss: 1.1795 - val_accuracy: 0.8638\n",
      "Epoch 393/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0276 - accuracy: 0.9890 - val_loss: 0.8945 - val_accuracy: 0.8671\n",
      "Epoch 394/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0279 - accuracy: 0.9900 - val_loss: 1.3271 - val_accuracy: 0.8704\n",
      "Epoch 395/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0338 - accuracy: 0.9882 - val_loss: 0.7518 - val_accuracy: 0.8691\n",
      "Epoch 396/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0230 - accuracy: 0.9929 - val_loss: 1.4090 - val_accuracy: 0.8691\n",
      "Epoch 397/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0290 - accuracy: 0.9894 - val_loss: 0.9870 - val_accuracy: 0.8658\n",
      "Epoch 398/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0333 - accuracy: 0.9882 - val_loss: 1.1763 - val_accuracy: 0.8664\n",
      "Epoch 399/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0340 - accuracy: 0.9887 - val_loss: 1.1598 - val_accuracy: 0.8751\n",
      "Epoch 400/400\n",
      "151/151 [==============================] - 1s 4ms/step - loss: 0.0244 - accuracy: 0.9910 - val_loss: 1.0844 - val_accuracy: 0.8751\n"
     ]
    }
   ],
   "source": [
    "batch_size = 40\n",
    "epochs = 400\n",
    "\n",
    "history = model.fit(X_train, y_train, \n",
    "                    batch_size=batch_size, \n",
    "                    epochs=epochs,\n",
    "                    verbose=1, \n",
    "                    validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a6a53a",
   "metadata": {},
   "source": [
    "### Evaluando el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed42b1b6",
   "metadata": {},
   "source": [
    "Se evalúa el modelo en la pérdida (i.e., loss) y precisión (i.e., accuracy) final."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5532a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.0844417810440063\n",
      "Test accuracy: 0.8750830292701721\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e5ec961",
   "metadata": {},
   "source": [
    "Visualizamos también el aumento en la precisión y la reducción de la pérdida a través de los epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0d0e52fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,7])\n",
    "plt.title('Increase in accuracy\\n', fontsize =15)\n",
    "plt.ylabel('Accuracy',fontsize=14)\n",
    "plt.xlabel('Epochs',fontsize=14)\n",
    "plt.ylim([0,1])\n",
    "plt.grid(linewidth=0.4)\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "50c43f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[10,7])\n",
    "plt.title('Decrease in loss\\n', fontsize =15)\n",
    "plt.ylabel('Loss',fontsize=14)\n",
    "plt.xlabel('Epochs',fontsize=14)\n",
    "plt.ylim([0,1])\n",
    "plt.grid(linewidth=0.4)\n",
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae9c96f",
   "metadata": {},
   "source": [
    "Visualizamos también cómo de adecuada es la clasificación en una matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "304d235d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, None, 153) for input KerasTensor(type_spec=TensorSpec(shape=(None, None, 153), dtype=tf.float32, name='dense_input'), name='dense_input', description=\"created by layer 'dense_input'\"), but it was called on an input with incompatible shape (None, 153).\n",
      "Classification accuracy: 0.8750830564784053\n",
      "Details for the confusion matrix: [[581 122]\n",
      " [ 66 736]]\n",
      "Confusion matrix: None\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Making 'y' a binary vector again \n",
    "y_testbinary = y_test.argmax(axis=1)\n",
    "y_predbinary = y_pred.argmax(axis=1)\n",
    "\n",
    "def plot_confusion_matrix(a, b):\n",
    "    plt.imshow(metrics.confusion_matrix(a, b),\n",
    "               cmap=plt.cm.gray, interpolation='nearest')\n",
    "    cbar = plt.colorbar()\n",
    "    plt.title('Confusion matrix\\n');\n",
    "    plt.xlabel('Predicted Version');\n",
    "    plt.ylabel('Actual Version');\n",
    "    plt.xticks([0, 1], ['Incorrect','Correct'])\n",
    "    plt.yticks([0, 1], ['Incorrect','Correct'])\n",
    "    cbar.set_label('Cases', rotation=90,fontsize=13)\n",
    "\n",
    "def details_confusion_matrix(a,b):\n",
    "    details = metrics.confusion_matrix(a,b)\n",
    "    return details\n",
    "\n",
    "print (\"Classification accuracy:\", metrics.accuracy_score(y_testbinary, y_predbinary))\n",
    "print(\"Details for the confusion matrix:\", details_confusion_matrix(y_testbinary, y_predbinary))\n",
    "print(\"Confusion matrix:\", plot_confusion_matrix(y_testbinary, y_predbinary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd3732d",
   "metadata": {},
   "source": [
    "## 3. Prediciendo ilusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "557e12b8",
   "metadata": {},
   "source": [
    "Hasta ahora se ha construido un modelo que funciona adecuadamente para clasificar si el ítem que lee un individuo se ha presentado en su versión correcta o incorrecta. Sin embargo, los datos con los que hemos entrenado el modelo son ensayos en los que los individuos conocen si el ítem es correcto o incorrecto, y además responden correctamente. \n",
    "\n",
    "Sin embargo, una parte importante de los resultados de la investigación original corresponde a los ensayos en los que se dan las ilusiones semánticas. Estas ilusiones suponen un error sistemático de los participantes, al contestar que oraciones incorrectas son correctas (e.g., Moisés llevó dos animales de cada tipo en el arca). Para observar si el modelo elaborado sirve como medida de integración semántica, debería hacer predicciones sistemáticamente erróneas para estos ensayos. Es decir, los debería clasificar como 'correctos', pues los sujetos de esos ensayos los han integrado como semánticamente coherentes. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b646fee",
   "metadata": {},
   "source": [
    "### Abriendo los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2341dce8",
   "metadata": {},
   "source": [
    "Empleamos ahora los datos de los ensayos en los que sucedió la ilusión semántica, es decir, ensayos en los que los sujetos respondieron que oraciones incorrectas eran correctas. Los guardamos bajo un DataFrame denominado 'dataillusions'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c6a2d9dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     predict          ms  lang  expo  pref       use  profic  grupo  orden  \\\n",
      "0          0   48.446809     0  1.00  1.00  0.912500   0.875      0      0   \n",
      "1          0   61.380952     0  0.20  0.80  0.468750   1.000      0      0   \n",
      "2          0   66.785714     0  0.80  0.50  0.756250   0.975      0      0   \n",
      "3          0  128.047619     0  0.60  0.50  0.712500   1.000      0      0   \n",
      "4          0   84.190476     0  0.80  0.85  0.862500   0.975      0      0   \n",
      "..       ...         ...   ...   ...   ...       ...     ...    ...    ...   \n",
      "496        0   65.835052     0  0.25  0.30  0.206250   1.000      1      1   \n",
      "497        0  107.049180     0  0.65  0.45  0.614286   0.775      1      1   \n",
      "498        0   61.520408     1  0.40  0.30  0.350000   0.950      1      0   \n",
      "499        0   86.462963     1  0.05  0.10  0.000000   0.925      1      0   \n",
      "500        0   85.296296     1  0.00  0.50  0.002500   0.850      1      1   \n",
      "\n",
      "     item  \n",
      "0       1  \n",
      "1       1  \n",
      "2       1  \n",
      "3       1  \n",
      "4       1  \n",
      "..    ...  \n",
      "496    74  \n",
      "497    74  \n",
      "498    74  \n",
      "499    74  \n",
      "500    74  \n",
      "\n",
      "[501 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "dataillusions = pd.read_csv('https://github.com/anabautistamartin/capstonedatasci/files/8984240/datasetillusions.csv',sep=';',header=None, decimal=',')\n",
    "\n",
    "dataillusions.columns = ['predict', 'ms', 'lang', 'expo', 'pref', 'use', 'profic', 'grupo', 'orden', 'item']\n",
    "print(dataillusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262d3698",
   "metadata": {},
   "source": [
    "### Haciendo one-hot-encoding de la columna 'item'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f7ea3bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     1   2   3   4   5   6   7   8   9   11  ...  64  66  67  68  69  70  71  \\\n",
      "0     1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "1     1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "2     1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "3     1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "4     1   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
      "496   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "497   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "498   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "499   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "500   0   0   0   0   0   0   0   0   0   0  ...   0   0   0   0   0   0   0   \n",
      "\n",
      "     72  73  74  \n",
      "0     0   0   0  \n",
      "1     0   0   0  \n",
      "2     0   0   0  \n",
      "3     0   0   0  \n",
      "4     0   0   0  \n",
      "..   ..  ..  ..  \n",
      "496   0   0   1  \n",
      "497   0   0   1  \n",
      "498   0   0   1  \n",
      "499   0   0   1  \n",
      "500   0   0   1  \n",
      "\n",
      "[501 rows x 71 columns]\n",
      "     predict          ms  lang  expo  pref       use  profic  grupo  orden  1  \\\n",
      "0          0   48.446809     0  1.00  1.00  0.912500   0.875      0      0  1   \n",
      "1          0   61.380952     0  0.20  0.80  0.468750   1.000      0      0  1   \n",
      "2          0   66.785714     0  0.80  0.50  0.756250   0.975      0      0  1   \n",
      "3          0  128.047619     0  0.60  0.50  0.712500   1.000      0      0  1   \n",
      "4          0   84.190476     0  0.80  0.85  0.862500   0.975      0      0  1   \n",
      "..       ...         ...   ...   ...   ...       ...     ...    ...    ... ..   \n",
      "496        0   65.835052     0  0.25  0.30  0.206250   1.000      1      1  0   \n",
      "497        0  107.049180     0  0.65  0.45  0.614286   0.775      1      1  0   \n",
      "498        0   61.520408     1  0.40  0.30  0.350000   0.950      1      0  0   \n",
      "499        0   86.462963     1  0.05  0.10  0.000000   0.925      1      0  0   \n",
      "500        0   85.296296     1  0.00  0.50  0.002500   0.850      1      1  0   \n",
      "\n",
      "     ...  64  66  67  68  69  70  71  72  73  74  \n",
      "0    ...   0   0   0   0   0   0   0   0   0   0  \n",
      "1    ...   0   0   0   0   0   0   0   0   0   0  \n",
      "2    ...   0   0   0   0   0   0   0   0   0   0  \n",
      "3    ...   0   0   0   0   0   0   0   0   0   0  \n",
      "4    ...   0   0   0   0   0   0   0   0   0   0  \n",
      "..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
      "496  ...   0   0   0   0   0   0   0   0   0   1  \n",
      "497  ...   0   0   0   0   0   0   0   0   0   1  \n",
      "498  ...   0   0   0   0   0   0   0   0   0   1  \n",
      "499  ...   0   0   0   0   0   0   0   0   0   1  \n",
      "500  ...   0   0   0   0   0   0   0   0   0   1  \n",
      "\n",
      "[501 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "dummies_item = pd.get_dummies(dataillusions['item'])\n",
    "print(dummies_item)\n",
    "\n",
    "datasetillusions = pd.merge(\n",
    "    left=dataillusions,\n",
    "    right=dummies_item,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    ")\n",
    "\n",
    "del datasetillusions['item']\n",
    "\n",
    "print(datasetillusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7f78a0",
   "metadata": {},
   "source": [
    "### Normalizando 'ms'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "554833f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0.122195\n",
      "1      0.172196\n",
      "2      0.193089\n",
      "3      0.429913\n",
      "4      0.260372\n",
      "         ...   \n",
      "496    0.189414\n",
      "497    0.348738\n",
      "498    0.172735\n",
      "499    0.269157\n",
      "500    0.264647\n",
      "Name: ms, Length: 501, dtype: float64\n",
      "     predict        ms  lang  expo  pref       use  profic  grupo  orden  1  \\\n",
      "0          0  0.122195     0  1.00  1.00  0.912500   0.875      0      0  1   \n",
      "1          0  0.172196     0  0.20  0.80  0.468750   1.000      0      0  1   \n",
      "2          0  0.193089     0  0.80  0.50  0.756250   0.975      0      0  1   \n",
      "3          0  0.429913     0  0.60  0.50  0.712500   1.000      0      0  1   \n",
      "4          0  0.260372     0  0.80  0.85  0.862500   0.975      0      0  1   \n",
      "..       ...       ...   ...   ...   ...       ...     ...    ...    ... ..   \n",
      "496        0  0.189414     0  0.25  0.30  0.206250   1.000      1      1  0   \n",
      "497        0  0.348738     0  0.65  0.45  0.614286   0.775      1      1  0   \n",
      "498        0  0.172735     1  0.40  0.30  0.350000   0.950      1      0  0   \n",
      "499        0  0.269157     1  0.05  0.10  0.000000   0.925      1      0  0   \n",
      "500        0  0.264647     1  0.00  0.50  0.002500   0.850      1      1  0   \n",
      "\n",
      "     ...  64  66  67  68  69  70  71  72  73  74  \n",
      "0    ...   0   0   0   0   0   0   0   0   0   0  \n",
      "1    ...   0   0   0   0   0   0   0   0   0   0  \n",
      "2    ...   0   0   0   0   0   0   0   0   0   0  \n",
      "3    ...   0   0   0   0   0   0   0   0   0   0  \n",
      "4    ...   0   0   0   0   0   0   0   0   0   0  \n",
      "..   ...  ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
      "496  ...   0   0   0   0   0   0   0   0   0   1  \n",
      "497  ...   0   0   0   0   0   0   0   0   0   1  \n",
      "498  ...   0   0   0   0   0   0   0   0   0   1  \n",
      "499  ...   0   0   0   0   0   0   0   0   0   1  \n",
      "500  ...   0   0   0   0   0   0   0   0   0   1  \n",
      "\n",
      "[501 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "datasetillusions['ms'] = MinMaxScaler().fit_transform(np.array(datasetillusions['ms']).reshape(-1,1)) \n",
    "  \n",
    "print(datasetillusions['ms'])\n",
    "print(datasetillusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe00745",
   "metadata": {},
   "source": [
    "### Separando la variable a predecir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b123a9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      0\n",
      "1      0\n",
      "2      0\n",
      "3      0\n",
      "4      0\n",
      "      ..\n",
      "496    0\n",
      "497    0\n",
      "498    0\n",
      "499    0\n",
      "500    0\n",
      "Name: predict, Length: 501, dtype: int64\n",
      "           ms  lang  expo  pref       use  profic  grupo  orden  1  2  ...  \\\n",
      "0    0.122195     0  1.00  1.00  0.912500   0.875      0      0  1  0  ...   \n",
      "1    0.172196     0  0.20  0.80  0.468750   1.000      0      0  1  0  ...   \n",
      "2    0.193089     0  0.80  0.50  0.756250   0.975      0      0  1  0  ...   \n",
      "3    0.429913     0  0.60  0.50  0.712500   1.000      0      0  1  0  ...   \n",
      "4    0.260372     0  0.80  0.85  0.862500   0.975      0      0  1  0  ...   \n",
      "..        ...   ...   ...   ...       ...     ...    ...    ... .. ..  ...   \n",
      "496  0.189414     0  0.25  0.30  0.206250   1.000      1      1  0  0  ...   \n",
      "497  0.348738     0  0.65  0.45  0.614286   0.775      1      1  0  0  ...   \n",
      "498  0.172735     1  0.40  0.30  0.350000   0.950      1      0  0  0  ...   \n",
      "499  0.269157     1  0.05  0.10  0.000000   0.925      1      0  0  0  ...   \n",
      "500  0.264647     1  0.00  0.50  0.002500   0.850      1      1  0  0  ...   \n",
      "\n",
      "     64  66  67  68  69  70  71  72  73  74  \n",
      "0     0   0   0   0   0   0   0   0   0   0  \n",
      "1     0   0   0   0   0   0   0   0   0   0  \n",
      "2     0   0   0   0   0   0   0   0   0   0  \n",
      "3     0   0   0   0   0   0   0   0   0   0  \n",
      "4     0   0   0   0   0   0   0   0   0   0  \n",
      "..   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  \n",
      "496   0   0   0   0   0   0   0   0   0   1  \n",
      "497   0   0   0   0   0   0   0   0   0   1  \n",
      "498   0   0   0   0   0   0   0   0   0   1  \n",
      "499   0   0   0   0   0   0   0   0   0   1  \n",
      "500   0   0   0   0   0   0   0   0   0   1  \n",
      "\n",
      "[501 rows x 79 columns]\n"
     ]
    }
   ],
   "source": [
    "tagsillusions = datasetillusions[\"predict\"]\n",
    "print(tagsillusions)\n",
    "\n",
    "variablesillusions = datasetillusions\n",
    "del variablesillusions['predict']\n",
    "print(variablesillusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb6db4e4",
   "metadata": {},
   "source": [
    "### Añadiendo columnas para conseguir el size que admite el modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbd784a",
   "metadata": {},
   "source": [
    "Los datos de los ensayos en los que se tiene la ilusión se refieren sólo a los primeros 74 ítems de los 146 iniciales; en el resto de ítems no hubo ninguna ilusión. Añadimos columnas para alcanzar las 146 columnas del one-hot-encoding de los datos con los que se entrenó el modelo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15c74bc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ms  lang  expo  pref       use  profic  grupo  orden  1  2  ...  \\\n",
      "0    0.122195     0  1.00  1.00  0.912500   0.875      0      0  1  0  ...   \n",
      "1    0.172196     0  0.20  0.80  0.468750   1.000      0      0  1  0  ...   \n",
      "2    0.193089     0  0.80  0.50  0.756250   0.975      0      0  1  0  ...   \n",
      "3    0.429913     0  0.60  0.50  0.712500   1.000      0      0  1  0  ...   \n",
      "4    0.260372     0  0.80  0.85  0.862500   0.975      0      0  1  0  ...   \n",
      "..        ...   ...   ...   ...       ...     ...    ...    ... .. ..  ...   \n",
      "496  0.189414     0  0.25  0.30  0.206250   1.000      1      1  0  0  ...   \n",
      "497  0.348738     0  0.65  0.45  0.614286   0.775      1      1  0  0  ...   \n",
      "498  0.172735     1  0.40  0.30  0.350000   0.950      1      0  0  0  ...   \n",
      "499  0.269157     1  0.05  0.10  0.000000   0.925      1      0  0  0  ...   \n",
      "500  0.264647     1  0.00  0.50  0.002500   0.850      1      1  0  0  ...   \n",
      "\n",
      "     138  139  140  141  142  143  144  145  146  147  \n",
      "0      0    0    0    0    0    0    0    0    0    0  \n",
      "1      0    0    0    0    0    0    0    0    0    0  \n",
      "2      0    0    0    0    0    0    0    0    0    0  \n",
      "3      0    0    0    0    0    0    0    0    0    0  \n",
      "4      0    0    0    0    0    0    0    0    0    0  \n",
      "..   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
      "496    0    0    0    0    0    0    0    0    0    0  \n",
      "497    0    0    0    0    0    0    0    0    0    0  \n",
      "498    0    0    0    0    0    0    0    0    0    0  \n",
      "499    0    0    0    0    0    0    0    0    0    0  \n",
      "500    0    0    0    0    0    0    0    0    0    0  \n",
      "\n",
      "[501 rows x 153 columns]\n"
     ]
    }
   ],
   "source": [
    "for i in range(74, 148):\n",
    "    variablesillusions[f'{i}']=0\n",
    "print(variablesillusions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46481492",
   "metadata": {},
   "source": [
    "### Creando predicciones para las ilusiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4656a81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 1 0 0 0 0 1 1 1 1 0 1 0 1 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 0 1 0\n",
      " 0 0 1 1 0 1 0 0 0 1 0 1 1 0 0 1 0 1 0 1 1 0 0 1 1 0 1 0 0 1 0 0 0 0 1 0 1\n",
      " 0 1 1 0 1 1 1 1 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0 0 0 0 0 1 1 1 1 1 0 1 1 1\n",
      " 1 1 1 0 1 0 0 0 0 0 1 0 0 1 1 1 1 0 1 0 1 1 1 1 1 1 0 1 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 0 0 0 0 0 1 1 0 0 1 1 1 1 1 1 1 0 0 0 0 1\n",
      " 1 0 0 0 1 1 0 0 1 1 1 0 0 0 1 1 0 1 1 0 1 1 1 1 1 0 0 1 1 1 0 0 0 1 1 1 0\n",
      " 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 1 1 0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 1 1 1 1\n",
      " 1 1 1 1 0 1 0 1 0 1 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 0 1 0 0 1 0 0 0 0 0 0 1\n",
      " 1 0 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 0 1 1 0 0 1 1 0 1 1 0 0 0 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 0 0\n",
      " 1 1 1 1 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 0 0 1 1 0 0 1 0 1 1 1 0 1 0 1 1 0 0\n",
      " 1 1 1 1 1 1 1 0 0 1 0 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 1 0 1 1 0 0 1 1 1\n",
      " 1 1 1 0 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 0 0 0 0 0 0 0 0 1 0 1 0 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "y_predillusions = model.predict(variablesillusions)\n",
    "\n",
    "# Making predicted 'y' a binary vector again \n",
    "y_predillusionsbinary = y_predillusions.argmax(axis=1)\n",
    "print(y_predillusionsbinary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf6394c",
   "metadata": {},
   "source": [
    "### Evaluando las predicciones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df06a9e",
   "metadata": {},
   "source": [
    "Evaluamos las predicciones del modelo para estos datos de ensayos con ilusiones semánticas mediante la accuracy y una matriz de confusión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "300e0f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification accuracy: 0.3912175648702595\n",
      "Confusion matrix: None\n",
      "Details for the confusion matrix: [[196 305]\n",
      " [  0   0]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Classification accuracy:\", metrics.accuracy_score(tagsillusions, y_predillusionsbinary))\n",
    "print(\"Confusion matrix:\", plot_confusion_matrix(tagsillusions, y_predillusionsbinary))\n",
    "print(\"Details for the confusion matrix:\", details_confusion_matrix(tagsillusions, y_predillusionsbinary))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e505c340",
   "metadata": {},
   "source": [
    "## 4. Conclusiones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf7dde3b",
   "metadata": {},
   "source": [
    "En este problema hemos intentado crear un clasificador que distinguiera ensayos en los que se presenta la versión correcta de una oración, y ensayos en los que se presenta la versión incorrecta. El modelo elaborado ha alcanzado una precisión de aproximadamente 0,88. Este resultado indica que el modelo puede predecir apropiadamente si una oración presentada a un sujeto es correcta o incorrecta, teniendo en cuenta el ítem leído, el tiempo de lectura del sujeto, sus variables sociolingüísticas en la lengua en la que se lee, y otras variables que discriminan el grupo al que pertenece el participante.\n",
    "\n",
    "Sin embargo, el objetivo inicial de este problema no era clasificar la coherencia semántica absoluta, sino la integración semántica que realiza cada individuo. En este sentido, los ensayos en los que aparecían ilusiones semánticas son extremadamente útiles. El modelo construido tuvo una precisión de aproximadamente 0,40 para esos ensayos, lo que indica que comete un error notable en línea con los resultados esperados. Sin embargo, se esperaría que clasificase esos ensayos como 'correctos', pues es el juicio semántico que hacen los sujetos, y no ocurre así para todos los casos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
